{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a51fcf7-8ff9-4f7b-bbfe-19a16e505b7a",
   "metadata": {},
   "source": [
    "In this notebook we will be testing zero-shot / few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6c6429-acac-4703-95f3-4f88fafba9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from llama_cpp import Llama\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "from mlflow_experiment import MlflowExperiment, EvaluationPipeline, InferencePipeline\n",
    "from mlflow_experiment.evaluation.metrics import (accuracy_score, \n",
    "                                                  precision,\n",
    "                                                  recall,\n",
    "                                                  false_negative_rate,\n",
    "                                                  false_positive_rate,\n",
    "                                                  median_response_token_count,\n",
    "                                                  median_query_token_count, \n",
    "                                                  median_processing_time, \n",
    "                                                  median_tokens_per_second, \n",
    "                                                  hallucination_rate, \n",
    "                                                  bad_output_format_rate)\n",
    "from mlflow_experiment.inference.prompt_building.basic_user_prompt_builder import (\n",
    "    BasicUserPromptBuilder,\n",
    ")\n",
    "from mlflow_experiment.inference.postprocessing.basic_postprocessing import (\n",
    "    BasicPostprocessing,\n",
    ")\n",
    "from mlflow_experiment.inference.model.basic_llama_cpp_model import BasicLlamaCppModel\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f192311-49ab-4f1e-ac22-5a539d8a7bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv(\"../.env\",override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be875a4a-1af5-400c-9b9c-6c5e8790e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"../data/subsample.jsonl\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24dbcbea-9f90-419d-b4c1-9b1a785f86e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_pipeline = EvaluationPipeline(accuracy_score,\n",
    "                                 precision,\n",
    "                                 recall,\n",
    "                                 false_negative_rate,\n",
    "                                 false_positive_rate,\n",
    "                                 median_response_token_count,\n",
    "                                 median_query_token_count,\n",
    "                                 median_processing_time,\n",
    "                                 median_tokens_per_second,\n",
    "                                 hallucination_rate,\n",
    "                                 bad_output_format_rate,\n",
    "                                 \n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5849402-9717-49dc-800e-c19dbdd024c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen2.5-1.5B-Instruct-Q5_K_M.gguf\"\n",
    "MODEL_PATH = f\"../models/{MODEL_NAME}\"\n",
    "model = Llama(MODEL_PATH, verbose=False, n_ctx=32768, n_gpu_layers=-1, n_batch=2048)\n",
    "\n",
    "prompt_builder = BasicUserPromptBuilder(\n",
    "    \"\"\"This is a movie review: {review}.\n",
    "    ----\n",
    "    Determine whether the overall sentiment of the review is positive or negative. You must look for evaluatory statements about the movie itself - e.g. \"thrilling\", \"terrible acting\", etc. These evaluatory statements are distinct from the movie genre! So be careful not to mistake descriptions about the genre. Take into account that different evaluatory statements might have different connation for different genres - e.g. a \"terrifying movie\" in the horror genre means a perfect movie, but in some other genre like commedy it might very well mean - rubbish movie.\n",
    "    ----\n",
    "    Your output: your output should be either \"positive\" (if the overall sentiment is positive) or \"negative\" (if the overall sentiment is negative). Do not output nothing more. Output only \"positive\" or \"negative\"!\n",
    "    \"\"\"\n",
    ")\n",
    "llama_model = BasicLlamaCppModel(model, user_prompt_builder=prompt_builder, model_name = MODEL_NAME)\n",
    "\n",
    "postprocessing_fn = BasicPostprocessing({\"negative\": 1, \"positive\": 0})\n",
    "\n",
    "inf_pipeline = InferencePipeline(\n",
    "    llama_model,\n",
    "    system_prompt=\"You are a sentiment analysis system. Your goal is to categorize movie reviews into positive or negative. Follow the instructions given precisely!\",\n",
    "    postprocessing_fn=postprocessing_fn,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5c45bcd-d905-48d1-ba08-f378d3902c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = MlflowExperiment(\n",
    "    inference_pipeline=inf_pipeline,\n",
    "    evaluation_pipeline=ev_pipeline,\n",
    "    experiment_name=\"zero-shot-few-shot-prompting\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad16cf4f-70d8-4c11-be79-79b0d3bcb73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [09:04<00:00, 18.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run FULL_DATASET_zero-shot-basic at: http://localhost:5000/#/experiments/173405608153165389/runs/0c8d2551607b4c65abe3079da3c8770d\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/173405608153165389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "temperature, top_k, top_p = 0.2, 40, 0.95\n",
    "#for temperature, top_k, top_p in product([0.2, 0.5, 1.0], [40, 500, 0], [0.95, 0.5, 0.0]):\n",
    "inference_outputs, evaluation_results = exp.run(\n",
    "    data[[\"review\"]].to_dict(orient=\"records\"),\n",
    "    y_true=data.label,\n",
    "    experiment_run_tags={\"justification\": \"Provide description of the task without concrete examples. \"},\n",
    "    run_name=f\"zero-shot-basic\",\n",
    "    temperature = temperature,\n",
    "    top_k = top_k,\n",
    "    top_p = top_p\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99deaf14-44a6-46e7-bf89-3cf613877f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_score': 0.9429,\n",
       " 'precision': np.float64(0.9531409862901575),\n",
       " 'recall': np.float64(0.9316),\n",
       " 'false_negative_rate': np.float64(0.06840000000000002),\n",
       " 'false_positive_rate': np.float64(0.0458),\n",
       " 'median_response_token_count': np.float64(1.0),\n",
       " 'median_query_token_count': np.float64(333.5),\n",
       " 'median_processing_time': np.float64(0.04989945888519287),\n",
       " 'median_tokens_per_second': np.float64(40.08059415280785),\n",
       " 'hallucination_rate': np.float64(0.0),\n",
       " 'bad_output_format_rate': np.float64(0.0)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bccd8396-cd50-4248-a09d-dfba3d7ba1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_outputs.loc[:, \"true\"] = data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "689723e5-c655-42eb-9192-796d4061ef59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_string</th>\n",
       "      <th>label</th>\n",
       "      <th>is_hallucination</th>\n",
       "      <th>is_wrong_format</th>\n",
       "      <th>input_token_count</th>\n",
       "      <th>output_token_count</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>290</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>469</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>508</td>\n",
       "      <td>1</td>\n",
       "      <td>0.049691</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>439</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>669</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>443</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>0.049850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1121 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     output_string  label  is_hallucination  is_wrong_format  \\\n",
       "0         positive      0             False            False   \n",
       "1         positive      0             False            False   \n",
       "2         negative      1             False            False   \n",
       "3         positive      0             False            False   \n",
       "4         positive      0             False            False   \n",
       "...            ...    ...               ...              ...   \n",
       "1116      positive      0             False            False   \n",
       "1117      positive      0             False            False   \n",
       "1118      positive      0             False            False   \n",
       "1119      positive      0             False            False   \n",
       "1120      positive      0             False            False   \n",
       "\n",
       "      input_token_count  output_token_count  elapsed_time  true  \n",
       "0                   290                   1      0.046078     0  \n",
       "1                   469                   1      0.040344     1  \n",
       "2                   508                   1      0.049691     1  \n",
       "3                   285                   1      0.034716     0  \n",
       "4                   439                   1      0.039175     0  \n",
       "...                 ...                 ...           ...   ...  \n",
       "1116                263                   1      0.026869     1  \n",
       "1117                442                   1      0.032223     0  \n",
       "1118                669                   1      0.045406     1  \n",
       "1119                443                   1      0.034034     0  \n",
       "1120                841                   1      0.049850     1  \n",
       "\n",
       "[1121 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d39f66-e5b9-4e96-bfca-6acb16e4eacc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
