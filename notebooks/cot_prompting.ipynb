{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a51fcf7-8ff9-4f7b-bbfe-19a16e505b7a",
   "metadata": {},
   "source": [
    "In this notebook we will be testing chain of thought prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6c6429-acac-4703-95f3-4f88fafba9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from llama_cpp import Llama\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "from mlflow_experiment import MlflowExperiment, EvaluationPipeline, InferencePipeline\n",
    "from mlflow_experiment.evaluation.metrics import (accuracy_score, \n",
    "                                                  precision,\n",
    "                                                  recall,\n",
    "                                                  false_negative_rate,\n",
    "                                                  false_positive_rate,\n",
    "                                                  median_response_token_count,\n",
    "                                                  median_query_token_count, \n",
    "                                                  median_processing_time, \n",
    "                                                  median_tokens_per_second, \n",
    "                                                  hallucination_rate, \n",
    "                                                  bad_output_format_rate)\n",
    "from mlflow_experiment.inference.prompt_building.basic_user_prompt_builder import (\n",
    "    BasicUserPromptBuilder,\n",
    ")\n",
    "from mlflow_experiment.inference.postprocessing.end_of_cot_postprocessing import (\n",
    "    EndOfCotPostprocessing, \n",
    ")\n",
    "from mlflow_experiment.inference.model.basic_llama_cpp_model import BasicLlamaCppModel\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f192311-49ab-4f1e-ac22-5a539d8a7bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv(\"../.env\",override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be875a4a-1af5-400c-9b9c-6c5e8790e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"../data/subsample.jsonl\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24dbcbea-9f90-419d-b4c1-9b1a785f86e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_pipeline = EvaluationPipeline(accuracy_score,\n",
    "                                 precision,\n",
    "                                 recall,\n",
    "                                 false_negative_rate,\n",
    "                                 false_positive_rate,\n",
    "                                 median_response_token_count,\n",
    "                                 median_query_token_count,\n",
    "                                 median_processing_time,\n",
    "                                 median_tokens_per_second,\n",
    "                                 hallucination_rate,\n",
    "                                 bad_output_format_rate,\n",
    "                                 \n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5849402-9717-49dc-800e-c19dbdd024c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_init_from_model: n_ctx_per_seq (5024) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"Qwen2.5-1.5B-Instruct-Q5_K_M.gguf\"\n",
    "MODEL_PATH = f\"../models/{MODEL_NAME}\"\n",
    "model = Llama(MODEL_PATH, verbose=False, n_ctx=5000, n_gpu_layers=-1, n_batch=4048)\n",
    "\n",
    "prompt_builder = BasicUserPromptBuilder(\n",
    "    \"\"\"This is a movie review: {review}.\n",
    "    ----\n",
    "    Determine whether the overall sentiment of the review is positive or negative. You must look for evaluatory statements about the movie itself - e.g. \"thrilling\", \"terrible acting\", etc. These evaluatory statements are distinct from the movie genre! So be careful not to mistake descriptions about the genre. Take into account that different evaluatory statements might have different connation for different genres - e.g. a \"terrifying movie\" in the horror genre means a perfect movie, but in some other genre like commedy it might very well mean - rubbish movie.\n",
    "    ----\n",
    "    Summarize the parts of the review which provide such evaluatory statements in a few words (just a few words, please!) and after that state you final estimation given the statements you have just extracted. Your output should be in the following format:\n",
    "    EXAMPLE of correct format 1:\n",
    "    \"The person generally loves action movies and this one provided great action sequences, beautiful cast and a lot of fast cars. Given these observations, my classification is: positive.\"\n",
    "    EXAMPLE of correct format 2:\n",
    "    \"The person found this movie dull and lackluster. Given these observations, my classification is: negative.\"\n",
    "    ----\n",
    "    If you are wrong 100000 little cute kittens will die a terrible death!!! YOU MUST BE CORRECT!\n",
    "    ----\n",
    "    You must end your statement with: \"my classification is:\" followed by the \"positive\" (when the overall sentiment is positive) and \"negative\" (when the overall sentiment is negative). Follow the format correctly! Be very concise in you summary - just a few words, nothing more!!!\n",
    "    \"\"\"\n",
    ")\n",
    "llama_model = BasicLlamaCppModel(model, user_prompt_builder=prompt_builder, model_name = MODEL_NAME)\n",
    "\n",
    "postprocessing_fn = EndOfCotPostprocessing(label_mapping={\"negative\": 1, \"positive\": 0}, end_of_cot_pattern=\"my classification is:\")\n",
    "\n",
    "inf_pipeline = InferencePipeline(\n",
    "    llama_model,\n",
    "    system_prompt=\"You are a sentiment analysis system. Your goal is to categorize movie reviews into positive or negative. Follow the instructions given precisely!\",\n",
    "    postprocessing_fn=postprocessing_fn,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5c45bcd-d905-48d1-ba08-f378d3902c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = MlflowExperiment(\n",
    "    inference_pipeline=inf_pipeline,\n",
    "    evaluation_pipeline=ev_pipeline,\n",
    "    experiment_name=\"zero-shot-few-shot-prompting\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad16cf4f-70d8-4c11-be79-79b0d3bcb73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [08:24<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run chain-of-thought-kittens at: http://localhost:5000/#/experiments/173405608153165389/runs/03ab424d42bc4a64a1e37daaad1fe887\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/173405608153165389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "temperature = 0.2\n",
    "top_k = 40\n",
    "top_p = 0.95\n",
    "inference_outputs, evaluation_results = exp.run(\n",
    "    data[[\"review\"]].to_dict(orient=\"records\"),\n",
    "    y_true=data.label,\n",
    "    experiment_run_tags={\"justification\": \"Provide description of the task without concrete examples. \"},\n",
    "    run_name=f\"chain-of-thought-kittens\",\n",
    "    temperature = temperature,\n",
    "    top_k = top_k,\n",
    "    top_p = top_p\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99deaf14-44a6-46e7-bf89-3cf613877f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_score': 0.7005347593582888,\n",
       " 'precision': np.float64(0.6481927710843374),\n",
       " 'recall': np.float64(0.9590017825311943),\n",
       " 'false_negative_rate': np.float64(0.04099821746880572),\n",
       " 'false_positive_rate': np.float64(0.5204991087344029),\n",
       " 'median_response_token_count': np.float64(33.0),\n",
       " 'median_query_token_count': np.float64(601.0),\n",
       " 'median_processing_time': np.float64(0.2654992341995239),\n",
       " 'median_tokens_per_second': np.float64(232.05322751152633),\n",
       " 'hallucination_rate': np.float64(0.0),\n",
       " 'bad_output_format_rate': np.float64(0.035650623885918005)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bccd8396-cd50-4248-a09d-dfba3d7ba1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_outputs.loc[:, \"true\"] = data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "689723e5-c655-42eb-9192-796d4061ef59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my classification is: positive'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_outputs.iloc[0].output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8d39f66-e5b9-4e96-bfca-6acb16e4eacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       " 1    139\n",
       "-1     82\n",
       " 0     11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_outputs[(inference_outputs.label != inference_outputs.true)].label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "286d54ac-2535-4d72-9cda-4a6e0d81de32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_string</th>\n",
       "      <th>label</th>\n",
       "      <th>is_hallucination</th>\n",
       "      <th>is_wrong_format</th>\n",
       "      <th>input_token_count</th>\n",
       "      <th>output_token_count</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [output_string, label, is_hallucination, is_wrong_format, input_token_count, output_token_count, elapsed_time, true]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_outputs[inference_outputs.is_hallucination]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3050aac6-6a29-4a27-a730-6f33938db939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_string</th>\n",
       "      <th>label</th>\n",
       "      <th>is_hallucination</th>\n",
       "      <th>is_wrong_format</th>\n",
       "      <th>input_token_count</th>\n",
       "      <th>output_token_count</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>965</td>\n",
       "      <td>1</td>\n",
       "      <td>0.054796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The overall sentiment of the review is positive.</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1451</td>\n",
       "      <td>9</td>\n",
       "      <td>0.112268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>654</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1189</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067887</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>591</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>980</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1246</td>\n",
       "      <td>1</td>\n",
       "      <td>0.069126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>positive</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>810</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047748</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>Example 1:\\n\"The person generally loves action...</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1281</td>\n",
       "      <td>67</td>\n",
       "      <td>0.366049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          output_string  label  \\\n",
       "14                                             positive     -1   \n",
       "16                                             positive     -1   \n",
       "17     The overall sentiment of the review is positive.     -1   \n",
       "18                                             positive     -1   \n",
       "24                                             negative     -1   \n",
       "...                                                 ...    ...   \n",
       "1050                                           positive     -1   \n",
       "1057                                           positive     -1   \n",
       "1072                                           positive     -1   \n",
       "1092                                           positive     -1   \n",
       "1107  Example 1:\\n\"The person generally loves action...     -1   \n",
       "\n",
       "      is_hallucination  is_wrong_format  input_token_count  \\\n",
       "14               False             True                965   \n",
       "16               False             True               1167   \n",
       "17               False             True               1451   \n",
       "18               False             True                654   \n",
       "24               False             True               1189   \n",
       "...                ...              ...                ...   \n",
       "1050             False             True                591   \n",
       "1057             False             True                980   \n",
       "1072             False             True               1246   \n",
       "1092             False             True                810   \n",
       "1107             False             True               1281   \n",
       "\n",
       "      output_token_count  elapsed_time  true  \n",
       "14                     1      0.054796     1  \n",
       "16                     1      0.067690     0  \n",
       "17                     9      0.112268     0  \n",
       "18                     1      0.045040     0  \n",
       "24                     1      0.067887     1  \n",
       "...                  ...           ...   ...  \n",
       "1050                   1      0.042982     0  \n",
       "1057                   1      0.055128     0  \n",
       "1072                   1      0.069126     0  \n",
       "1092                   1      0.047748     0  \n",
       "1107                  67      0.366049     0  \n",
       "\n",
       "[82 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_outputs[inference_outputs.is_wrong_format]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3541a986-d23a-4c16-a4a5-d0552ec96e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
